
<ul>
<li>Introduction<ac_link ac:anchor="Introduction"/></li>
<ul>
<li>QLA Functionality<ac_link ac:anchor="QLA_Functionality"/></li>
<ul>
<li>Logical Components<ac_link ac:anchor="Logical_Components"/></li>
<li>Functionality Domains<ac_link ac:anchor="Functionality_Domains"/></li>
</ul>
</ul>
<li>The QLA Processing Framework (QPF)<ac_link ac:anchor="The_QLA_Processing_Framework_(QPF)"/></li>
<ul>
<li>QPF Overall Architecture<ac_link ac:anchor="QPF_Overall_Architecture"/></li>
<li>QPF Components<ac_link ac:anchor="QPF_Components"/></li>
<ul>
<li>Event Manager<ac_link ac:anchor="Event_Manager"/></li>
<li>HMI<ac_link ac:anchor="HMI"/></li>
<li>QPF Database<ac_link ac:anchor="QPF_Database"/></li>
<li>Data Manager<ac_link ac:anchor="Data_Manager"/></li>
<li>Log Manager<ac_link ac:anchor="Log_Manager"/></li>
<li>Orchestrator<ac_link ac:anchor="Orchestrator"/></li>
<li>Task Manager<ac_link ac:anchor="Task_Manager"/></li>
<li>Task Agent(s)<ac_link ac:anchor="Task_Agent(s)"/></li>
<li>Processing Elements<ac_link ac:anchor="Processing_Elements"/></li>
</ul>
</ul>
<li>QPF Software Installation<ac_link ac:anchor="QPF_Software_Installation"/></li>
<ul>
<li>Pre-requisites<ac_link ac:anchor="Pre-requisites"/></li>
<li>Pre-installation tasks<ac_link ac:anchor="Pre-installation_tasks"/></li>
<ul>
<li>COTS installation<ac_link ac:anchor="COTS_installation"/></li>
<li>Obtaining the Source Code<ac_link ac:anchor="Obtaining_the_Source_Code"/></li>
<li>Pre-building environment settings<ac_link ac:anchor="Pre-building_environment_settings"/></li>
<li>Installation Procedure<ac_link ac:anchor="Installation_Procedure"/></li>
<li>Post-installation<ac_link ac:anchor="Post-installation"/></li>
<li>Installation tests<ac_link ac:anchor="Installation_tests"/></li>
<li>Uninstallation Procedure<ac_link ac:anchor="Uninstallation_Procedure"/></li>
<hr/>
</ul>
</ul>
<li>QPF Internals<ac_link ac:anchor="QPF_Internals"/></li>
<ul>
<li>Technologies<ac_link ac:anchor="Technologies"/></li>
<li>Specification<ac_link ac:anchor="Specification"/></li>
<ul>
<li>QPF Database Specification<ac_link ac:anchor="QPF_Database_Specification"/></li>
<li>Sample QPF Configuration<ac_link ac:anchor="Sample_QPF_Configuration"/></li>
<li>Alarm System<ac_link ac:anchor="Alarm_System"/></li>
</ul>
</ul>
</ul>

<h2>Introduction<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Introduction</ac:parameter></ac:structured-macro></h2>
<p>The main elements interfacing each other at the mission operation phase are the <strong>Science Operations Centre</strong> (SOC) and the <strong>Mission Operations Centre</strong> (MOC). In addition, there are two <strong>Instrument Operations Teams</strong> (IOTs), responsible for the definition of the instrument operational procedures as well as to ensure the operability of the different instruments along the mission.</p>
<p>In particular,  the <strong>Science Operations Centre</strong> at ESAC is the responsible of the Survey execution. It generates the required commanding requests to ensure its fulfilment as well as the routine calibration plan. It also acts as formal interface from the IOTâ€™s to the MOC during the routine mission, consolidating instrument operational requests against the on-going survey, and if required and not covered by a coordinating IOT entity, across instrument consolidation. It is part of the Instrument Monitoring to provide a quick look assessment on the instrument performance and survey execution.</p>
<p>The SOC is the entity responsible to gather the data provided by the MOC and make it available to the rest of the Science Ground Segment in appropriate format, generating the Level 1. This Level 1 is foreseen that will comprise the scientific, house-keeping and ancillary information received from MOC.</p>
<p>The SOC is composed of several subsystems.  Among them, the <strong>Quick Look Analysis</strong> (<strong>QLA</strong>) subsystem is devoted to automatically check S/C data, produce and ingest reports in the Euclid Archive System within 48 hours from data retrieval to confirm that the data are correct and eventually quickly react to issue; the IOT (instrument operation team) and EC (Euclid consortium) will investigate the data in further details, but in can take some weeks as the data is foreseen to be reduced once a larger sky patch has been observed.  In addition, the QLA will facilitate data inspection by the user (mainly instrument scientists) in case further data inspection is needed, e.g. being capable of accessing detectors data, showing it and/or exporting it to external programs.</p>
<h3>QLA Functionality<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">QLA_Functionality</ac:parameter></ac:structured-macro></h3>
<h4>Logical Components<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Logical_Components</ac:parameter></ac:structured-macro></h4>
<p> The following is a list of the logical QLA components:</p>
<ul>
  <li>
    <u>QLA-VIM</u> - Visualization and MMI: Set of components supporting data visualization and human analysis routines. It interacts internally with the CAM module for different configurations and runs.</li>
  <li>
    <u>QLA-SIF</u> - SOC Interface: Interface to other SOC components, and to external data received at SOC. It includes the interface with EAS.</li>
  <li>
    <u>QLA-SDA</u> - Science Data Analysis: Set of routines analysing the science images. It deals with pixel data analysis.</li>
  <li>
    <u>QLA-REP</u> - Reporting: Component in charge of automatic report generation.</li>
  <li>
    <u>QLA-QAF</u> - Quality Analysis Flagging: In charge of setting and defining values of predefined flags and fields from the analysis to be used for LE1 product expansion</li>
  <li>
    <u>QLA-PDA</u> - PUS Data Analysis: Set of routines analysing the PUS (HKTM) data</li>
  <li>
    <u>QLA-PAR</u> - Parameter Extraction: Component in charge of extraction of time based parameters from the analysis and export as files to be used by the HMS. It is TBD if this component shall only generate the Science and Auxiliary</li>
  <li>
    <u>QLA-CDA</u> - Combined Data Analysis: Set of routines implementing a combined analysis across science (inter-instrument, multi- dither), and/or across pixel and other type of data: PUS and ancillary data</li>
  <li>
    <u>QLA-CAM</u> - Configuration and Monitoring: Configuration of the subsystem, including specific information related to the data to be analysed (extracted from ESS). Monitor of performance and generation of log data. It also updates system configuration based on external sources (i.e. HMS reports and or limits)</li>
  <li>
    <u>QLA-ADA</u> - Auxiliary Data Analysis: Set of routines analysing the MOC and other ancillary data (ESS, Configuration)QLA-PRO - Processing: Routines to process raw or LE1 data if required with support of calibrated data to the required level for the analysis</li>
</ul>
<h4>Functionality Domains<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Functionality_Domains</ac:parameter></ac:structured-macro></h4>
<p>The QLA Logical Decomposition shown above in the previous section is a good way to study the entire functionality of the QLA.  In practice, however, we defined two different <strong>Functionality Domains</strong>:</p>
<ul>
  <li>
    <strong>QLA Processing/Algorithmic Functions</strong>: It is formed by the set of libraries and processing elements that perform the different analysis on the input data.</li>
  <li>
    <strong>QLA Processing Framework</strong>: It has an entire set of different functions to provide the infrastructure needed for the QLA processing:<ul>
      <li>reception and storage of input files and their metadata</li>
      <li>orchestration of the different processing tasks according to a set of pre-defined, user-modifiable rules,</li>
      <li>scheduling of the processing tasks to be executed upon rule firing</li>
      <li>monitoring of the different processing tasks</li>
      <li>storage of processing output products</li>
      <li>dissemination and reporting of the processing results</li>
      <li>incorporation of an interactive graphical user interface for the exploration of the processing results, including the ability to export input/output data for further processing and study to external tools</li>
    </ul>
  </li>
</ul>
<h2>The QLA Processing Framework (QPF)<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">The_QLA_Processing_Framework_(QPF)</ac:parameter></ac:structured-macro></h2>
<p>The intention is to create a framework for the execution of the different processing tasks that must be performed on the Euclid data (science products and calibration products) by the QLA.  In the following sections, We refer to this framework as the <strong>QPF</strong>.</p>
<p>The QPF will be composed of a set of elements that take the incoming external events and data, check their basic consistency, perform a specific orchestration based on the type of incoming data, and launches the necessary processing tasks to end up with the set of diagnostics, statistics and output parameters to evaluate the validity and quality of the products.  In section 1.2.3 a detailed description of them is provided.</p>
<h3>QPF Overall Architecture<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">QPF_Overall_Architecture</ac:parameter></ac:structured-macro></h3>
<p>The architecture of the QPF has the following main drivers:</p>
<ul>
  <li>
    <strong>Independent execution</strong>: Each of the components works independently of the others.</li>
  <li>
    <strong>Message-based communication</strong>: The activities of the different components are synchronised by means of message-based communication.  A single message can be sent by a component to any of the other components, to a group of them, or to the entire set of components.  Components process the messages they receive, and perform their tasks accordingly</li>
  <li>
    <strong>Service oriented</strong>: Each of the components behaves like a service provider element, acting upon request (after a message from another component).</li>
  <li>
    <strong>Encapsulated task execution</strong>: The Orchestration function provides to the Task Manager function the information about the processing task that must be executed on a data set.  The Task Manager function is deveoted to the lunching of the different tasks, that will be encapsulated and isolated from the main host system.  File based input and output is the only interface between the system and the different Processing Elements.</li>
  <li>
    <strong>Database storage</strong>: The configuration configuration, products metadata, task execution information, exchanged messages, alarms, etc. are stored in a dedicated database, to facilitate the system operation as well as the access form external applications to the overall system information.</li>
  <li>
    <strong>System persistence</strong>: The system establishes an strategy to allow it to be persistent upon failures.</li>
</ul>
<p>The overall architecture of the QPF is shown in the following figure.</p>
<p>
  <ac:image ac:alt="QPF Prototype Architecture" ac:border="true" ac:height="720" ac:queryparams="effects=drop-shadow" ac:title="QPF Prototype Architecture" ac:width="960">
    <ri:attachment ri:filename="QPF_Architecture.png"/>
  </ac:image>
</p>
<h3>QPF Components<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">QPF_Components</ac:parameter></ac:structured-macro></h3>
<h4>Event Manager<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Event_Manager</ac:parameter></ac:structured-macro></h4>
<p>The Event Manager is in charge of receiving all external input messages and process them. This processing most of the cases involves the transmission of new messages to other system components, requesting data saving or registration, task orchestration, etc.</p>
<p>A special data channel exists between the HMI and the Event Manager: the HMI shall be able to send messages to the Event Manager requesting some information, and the Event Manager shall asnwer these messages with the appropriate, available information.</p>
<h4>HMI<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">HMI</ac:parameter></ac:structured-macro></h4>
<p>The HMI has several functionalities:</p>
<ul>
  <li>provide information about the different actions and messages that take place in the system</li>
  <li>provide feedback to the operator on the processing status of the different processing tasks</li>
  <li>shows a view of the current status of the Data Manager registration area</li>
  <li>provides to the operator of the capability of sending fake input messages to the Event Manager (for testing purposes)</li>
  <li>upon request, provides information from the Event Manager on the current status of the entire system.</li>
</ul>
<h4>QPF Database<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">QPF_Database</ac:parameter></ac:structured-macro></h4>
<p>The entire set of data handled by the QPF, from the system configuration to the input/output products metadata, orchestration rules, etc. is stored in a central DB system. This simplifies the access of the system data to external tools.</p>
<h4>Data Manager<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Data_Manager</ac:parameter></ac:structured-macro></h4>
<p>The Data Manager is devoted to the registration of incoming products metadata. In this sense, whenever a processing task is delivered, the required input products metadata will be obtained from the Data Manager.</p>
<p>In case a data set (auxiliary files or whatsoever) is needed and has not been registered into the Data Manager, this component will perform a request to the Archive (TBD).</p>
<h4>Log Manager<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Log_Manager</ac:parameter></ac:structured-macro></h4>
<p>The Log Manager is in charge of synchronising the log information from the different system components.</p>
<h4>Orchestrator<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Orchestrator</ac:parameter></ac:structured-macro></h4>
<p>The orchestrator has the information about the processing elements that can be invoked whenever a set of input data products is available. When this processing can be invoked, a request is sent to the Task Manager with the appropriate information.</p>
<h4>Task Manager<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Task_Manager</ac:parameter></ac:structured-macro></h4>
<p>The Task Manager receives information about processing tasks that can be executed (that is, because its required input products are available). In turn, it selects one of the configured Task Agents for the purpose of executing and monitoring the requested processing task.</p>
<h4>Task Agent(s)<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Task_Agent(s)</ac:parameter></ac:structured-macro></h4>
<p>The Task Agents are the ultimate responsible for the execution of the different tasks. They:</p>
<ul>
  <li>receive all the neccessary information about these tasks,</li>
  <li>invoke the selected processing element,</li>
  <li>monitor the execution of the processing elements, and</li>
  <li>provide feedback on the resulting execution to the Task Manager.</li>
</ul>
<h4>Processing Elements<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Processing_Elements</ac:parameter></ac:structured-macro></h4>
<p>Each of the different processing algorithmic tasks that ultimately execute the final algorithms on the product data, and provide output information to be either disseminated or further processed by the system</p>
<p>In the current approach, the processing elements are tasks that run into Docker containers.</p>
<h2>QPF Software Installation<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">QPF_Software_Installation</ac:parameter></ac:structured-macro></h2>
<h3>Pre-requisites<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Pre-requisites</ac:parameter></ac:structured-macro></h3>
<p>QPF is a C++ application that makes use of some of the C++-11 new features of the C++ language. It was originally developed in an Ubuntu 15.10 box with a GCC compiler version 5.2.1 (Ubuntu 5.2.1-22ubuntu2 - 20151010). The compiler used to build the executables and libraries must cover most of the C++-11 features included in that GCC version.</p>
<p>One exception is the Regular Expressions matching component. Initially, the code made use of the functionality included in the C++-11 standard. However, for the sake of compatibility with earlier (non-fully C++-11 compliant) GCC versions, the regular expressions matching used now is the one included in the external library PCRE2. For the purposes of the QPF, the functionality included therein is more than enough.</p>
<p>The QPF Graphical User Interface (<code>qpfhmi</code>) is based on Qt 5.4.1 (GCC 4.6.1, 64 bit), built on Apr 22nd 2015 04:12:47 from revision 6302a28c97, and developed using Qt Creator 3.4.0 (open source).</p>
<p>The list of COTS is shown below.</p>
<h3>Pre-installation tasks<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Pre-installation_tasks</ac:parameter></ac:structured-macro></h3>
<h4>COTS installation<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">COTS_installation</ac:parameter></ac:structured-macro></h4>
<p>The QPF source code needs some COTS to be installed in the building host. It is assumed by this installation guide that these COTS are already installed.</p>
<p>The following is the list of COTS needed to build and run QPF Release V1. The version numbers shown in some of the COTS are used for reference: those versions or higher with backward-compatibility could be used. Where no version number appears, it means that any reasonably recent version should work. Note that the QPF source code also makes use of the JSONCpp library (v.1.6.2), although this library is already integrated in the source tree.</p>
<ul>
  <li>Qt 5.4</li>
  <li>0MQ Library (v-4.1.1), together with the C++ binding for 0MQ</li>
  <li>PostgreSQL (v-9.4.4.1 x64)</li>
  <li>PCRE2 (v-2.8)</li>
  <li>libcurl</li>
  <li>libsodium</li>
  <li>libuuid</li>
</ul>
<p>The PostsgreSQL database server must be started for the installation process to end successfully. By default, the server is listening for connection requests at <code>localhost:5432</code>. It you or your system administrator changes this address or port, you should specify the new values in the appropriate settings file (see below).</p>
<p>In addition, for the execution of the Unitary Tests, the library Google Test v-1.7 is used. However, this is not a requirement for compiling and installing the QPF.</p>
<h4>Obtaining the Source Code<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Obtaining_the_Source_Code</ac:parameter></ac:structured-macro></h4>
<p>The QPF source code for this release can be obtained from the Euclid SVN repository, using the following branch URL:</p>
<p>
  <a href="https://euclid.esac.esa.int/svn/ESA/SOC/SOC-3-DEV/SOC-3-07-QLook/QPF/branches/V1.0">https://euclid.esac.esa.int/svn/ESA/SOC/SOC-3-DEV/SOC-3-07-QLook/QPF/branches/V1.0</a>
</p>
<p>In order to fetch the source code, move to a folder where you want the system to store the code, and type:</p>
<pre>$ svn checkout https://euclid.esac.esa.int/svn/ESA/SOC/SOC-3-DEV/SOC-3-07-QLook/QPF/branches/V1.0 QPF-V1
</pre>
<p>The source code will be available under the folder QPF-V1.</p>
<p>Alternatively, if you got a QPF Release V1 source code package <code>QPF-V1.0-&lt;timestamp&gt;.tar.gz</code>, you can move to the desired folder and extract the source code files, as follows:</p>
<pre>$ tar xvzf &lt;source_path&gt;/QPF-V1.0-&lt;timestamp&gt;.tar.gz
</pre>
<p>where <code>&lt;source_path&gt;</code> is the place where the source code package is located.</p>
<h4>Pre-building environment settings<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Pre-building_environment_settings</ac:parameter></ac:structured-macro></h4>
<p>After getting the source code, but before starting the compilation &amp; installation process, you must set your environment. In particular, you should make sure the compilation system addresses correctly the appropriate COTS header and library files.</p>
<p>Note that the system by default assumes the following:</p>
<ul>
  <li>Your user name is <code>eucops</code> and your home folder is <code>/home/eucops</code>.</li>
  <li>The COTS needed to build and run the QPF are placed under the folder <code>${HOME}/opt</code>, in the following paths:<ul>
      <li>Qt (5.4): <code>${HOME}/opt/Qt</code>
      </li>
      <li>0MQ: <code>${HOME}/opt/zmq</code>
      </li>
      <li>PCRE2: <code>${HOME}/opt/pcre2</code>
      </li>
      <li>PostgreSQL: <code>${HOME}/opt/pgsql</code>
      </li>
      <li>libsodium: <code>${HOME}/opt/libsodium</code>
      </li>
      <li>Libcurl: <code>${HOME}/opt/curl</code>
      </li>
    </ul>
  </li>
</ul>
<p>If all these assumptions are met, you may not need to do the modifications described in the following two sections.</p>
<ul>
  <li>Environment Variables: There is a Bash script in the source code tree, where a bunch of environment variables are set for the compilation and execution of QPF. The script is <code>QPF-V1/env.sh</code>. You should first edit this file (modifying <strong>only</strong> the section <em>Basic variables</em>), and then run it with: "<code>source &lt;QPF_path&gt;/env.sh"</code> where <code>&lt;QPF_path&gt;</code> is the path where the QPF source code is located, including the <code>QPF-V1</code> part.</li>
  <li>Compilation Variables: In addition, similar information must be included in the file <code>QPF-V1/defaults.pri</code>, used by the building system. You must edit this file (only the section <em>External libraries</em>), and ensure the COTS are pointed to correctly by the paths defined therein.</li>
</ul>
<h4>Installation Procedure<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Installation_Procedure</ac:parameter></ac:structured-macro></h4>
<p>Once the appropriate environment is set, and the <code>defaults.pri</code> ensures the COTS are reachable, the compilation and installation process is rather automatic.</p>
<p>There is a compilation &amp; installation script, <code>QPF-V1/scripts/BuildQPF.sh</code>, that is used for this task. The actions performed by this script are:</p>
<ul>
  <li>Check that the needed programs for the compilation, installation and execution of QPF are installed.</li>
  <li>Check that the required libraries are installed and reachable.</li>
  <li>Generate the required dependencies between the different QPF components.</li>
  <li>Compile the QPF system.</li>
  <li>Set up the working (execution) area and install the sample configuration and processors.</li>
  <li>Install the QPF executable and libraries.</li>
  <li>(Re)generate the internal QPF database.</li>
</ul>
<p>Every action performed by this script is registered in a log file.</p>
<p>You can run this script by moving into the <code>QPF-V1/scripts</code> folder and typing in the console <code>./BuildQPF.sh -h</code>:</p>
<table bgcolor="#F5ECCE" border="1">
  <tbody>
    <tr>
      <td>
        <pre>$ ./BuildQPF.sh -h
Usage: BuildQPF.sh [ -h ] [ -c ] [ -i ] [ -n ] [ -r ] [ -b ] [ -w &lt;path&gt; ] [ -H &lt;host&gt; ] [ -P &lt;port&gt; ]
where:
  -h         Show this usage message
  -c         Compile the source code
  -i         Install libraries and binary
  -n         Show the actions without executing them
  -r         Clear previous build
  -b         Re-create PostsgreSQL system database
  -w &lt;path&gt;  Folder to locate QPF working area (default:HOME)
  -H &lt;host&gt;  Host where system database is located (default:localhost)
  -P &lt;port&gt;  Port to access the database (default:5432)
</pre>
      </td>
    </tr>
  </tbody>
</table>
<p>With the option <code>-h</code>, the script displays an usage message with the possible options. To start the compilation and installation process for the first time, with the default values for the working area folder and the PostsgreSQL server connections address and port, just type:</p>
<table bgcolor="#F5ECCE" border="1">
  <tbody>
    <tr>
      <td>
        <pre>$ ./BuildQPF.sh -c -i -r -b
</pre>
      </td>
    </tr>
  </tbody>
</table>
<p>The script will start performing all the actions needed for the preparation, compilation and installation of the QPF, as well as for the PostsgreSQL database initial setup. The option <code>-r</code> can be skipped the first time (it just removes any previous compiled object files), but it does no harm.</p>
<p>Note that specifying the option <code>-b</code> (database re-creation) will have the effect of removing completely any previous database with the same name (<code>qpfdb</code>) in the server.</p>
<p>Once the installation has finished, as indicated by the script you should:</p>
<ul>
  <li>include the directory <code>&lt;path&gt;/qpf/bin</code> in the <code>PATH</code> variable, and</li>
  <li>include the directory <code>&lt;path&gt;/qpf/lib</code> in the <code>LD_LIBRARY_PATH</code> variable.</li>
</ul>
<p>Note that <code>&lt;path&gt;</code> represents the folder where the QPF working area will be placed. By default this path is <code>${HOME}</code>.</p>
<p>Once the <code>PATH</code> and <code>LD_LIBRARY_PATH</code> variables are set, you can check if the QPF was correctly installed. The QPF operation is handled by the QPF HMI (<code>qpfhmi</code>). Just type:</p>
<table bgcolor="#F5ECCE" border="1">
  <tbody>
    <tr>
      <td>
        <pre>$ qpfhmi -h
        </pre>
      </td>
    </tr>
  </tbody>
</table>
<p>A help message should appear in the console.</p>
<p>Initial configuration files (in JSON) are available at <code>&lt;path&gt;/qpf/cfg</code>. You may need to modify them before launching any processing task from the HMI. If no configuration file is specified at command line, <code>qpfhmi</code> will read the last configuration used from the internal database.</p>
<h4>Post-installation<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Post-installation</ac:parameter></ac:structured-macro></h4>
<p>After installing the QPF, and before actually running the framework, the <code>Docker</code> application must be installed. <code>Docker</code> is assumed to be installed, and the user that runs QPF must be able to run any container.</p>
<h4>Installation tests<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Installation_tests</ac:parameter></ac:structured-macro></h4>
<p>TBC installation tests.</p>
<h4>Uninstallation Procedure<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Uninstallation_Procedure</ac:parameter></ac:structured-macro></h4>
<p>TBC</p>
<hr/>
<p>For any doubt or comment on the building and installation procedure here described, please do not hesitate to contact <a href="mailto:JCGonzalez@sciops.esa.int">JCGonzalez@sciops.esa.int</a>.</p>
<h2>QPF Internals<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">QPF_Internals</ac:parameter></ac:structured-macro></h2>
<h3>Technologies<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Technologies</ac:parameter></ac:structured-macro></h3>
<p>For the so-called QPF Toy Model (a proof of concept of the proposed QPF), the following technologies are planned to be used.</p>
<ul>
  <li>
    <strong>C++</strong>: All managment components will be coded in C++.</li>
  <li>
    <strong>Docker</strong>: Task Agents will be Docker containers, running independently, with an embeded Processing Element included and with file-based interface with the host system and with the Task Manager</li>
  <li>
    <strong>0MQ</strong>: Communications among the different managment components (all but the processing elements) will used Zero-MQ sockets for their communications</li>
  <li>
    <strong>Qt</strong>: The HMI component will be based on Qt and coded on C++. For the Toy Model, the HMI will be responsible also for providing appropriate input events and data to the system via the Event Manager.</li>
  <li>
    <strong>PostgreSQL</strong>: The system configuration, alarms, product metadata, etc. will be stored in a PostgreSQL database.</li>
  <li>
    <strong>PCRE2</strong>: File name templates will be compiled against PCRE2 library.</li>
  <li>
    <strong>Zabbix</strong>: Zabbix is proposed to be used as Monitoring solution for the entire set of components of the system. At the time of writing this document, Zabbix is not yet used, though.</li>
</ul>
<h3>Specification<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Specification</ac:parameter></ac:structured-macro></h3>
<p>This section contains obsolete structures and information, and is process of being updated.</p>
<h4>QPF Database Specification<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">QPF_Database_Specification</ac:parameter></ac:structured-macro></h4>
<p>The following figure shows a view of the QPF Internal Database structure:</p>
<p>
  <ac:image>
    <ri:attachment ri:filename="db.png"/>
  </ac:image> <br/> <br/> This structure can be created with the following code (PostgreSQL):</p>
<p> </p>
<table bgcolor="#F5ECCE" border="1">
  <tbody>
    <tr>
      <td>
        <pre>        CREATE TABLE "config_general" (
                "parameter" VARCHAR(32) NOT NULL,
                "content" VARCHAR(256) NOT NULL,
                CONSTRAINT config_general_pk PRIMARY KEY ("parameter")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "config_nodes" (
                "name" VARCHAR(20) NOT NULL,
                "type" VARCHAR(20) NOT NULL,
                "clientAddr" VARCHAR(128) NOT NULL,
                "serverAddr" VARCHAR(128) NOT NULL,
                CONSTRAINT config_nodes_pk PRIMARY KEY ("name")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "config_orchestration" (
                "ruleId" integer NOT NULL,
                "inputs" VARCHAR(1024) NOT NULL,
                "outputs" VARCHAR(1024) NOT NULL,
                "processorId" integer NOT NULL,
                CONSTRAINT config_orchestration_pk PRIMARY KEY ("ruleId","processorId")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "config_processors" (
                "processorId" integer NOT NULL,
                "processorName" VARCHAR(1024) NOT NULL,
                "exePath" VARCHAR(1024) NOT NULL,
                "inputPath" VARCHAR(1024) NOT NULL,
                "outputPath" VARCHAR(1024) NOT NULL,
                CONSTRAINT config_processors_pk PRIMARY KEY ("processorId")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "config_products" (
                "productType" VARCHAR(128) NOT NULL,
                CONSTRAINT config_products_pk PRIMARY KEY ("productType")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "products_info" (
                "id" integer NOT NULL,
                "productId" VARCHAR(256) NOT NULL,
                "productType" VARCHAR(128) NOT NULL,
                "productStatus" integer NOT NULL,
                "productVersion" VARCHAR(128) NOT NULL,
                "productSize" integer NOT NULL,
                "creatorId" integer NOT NULL,
                "instrumentId" integer NOT NULL,
                "obsMode" integer NOT NULL,
                "startTime" DATETIME NOT NULL,
                "endTime" DATETIME NOT NULL,
                "registrationTime" DATETIME NOT NULL,
                "url" VARCHAR(1024) NOT NULL,
                CONSTRAINT products_info_pk PRIMARY KEY ("id","productId","productType","productStatus","creatorId","instrumentId","obsMode")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "product_status" (
                "productStatus" integer NOT NULL,
                "statusDesc" integer NOT NULL,
                CONSTRAINT product_status_pk PRIMARY KEY ("productStatus")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "instruments" (
                "instrumentId" integer NOT NULL,
                "instrument" VARCHAR(128) NOT NULL,
                CONSTRAINT instruments_pk PRIMARY KEY ("instrumentId")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "creators" (
                "creatorId" integer NOT NULL,
                "creatorDesc" VARCHAR(128) NOT NULL,
                CONSTRAINT creators_pk PRIMARY KEY ("creatorId")
        ) WITH (
          OIDS=FALSE
        );

        CREATE TABLE "observation_modes" (
                "obsMode" integer NOT NULL,
                "obsModeDesc" VARCHAR(128) NOT NULL,
                CONSTRAINT observation_modes_pk PRIMARY KEY ("obsMode")
        ) WITH (
          OIDS=FALSE
        );


        ALTER TABLE "config_orchestration" ADD CONSTRAINT config_orchestration_fk0 FOREIGN KEY (processorId) REFERENCES config_processors(processorId);

        ALTER TABLE "products_info" ADD CONSTRAINT products_info_fk0 FOREIGN KEY (productStatus) REFERENCES product_status(productStatus);
        ALTER TABLE "products_info" ADD CONSTRAINT products_info_fk1 FOREIGN KEY (productType) REFERENCES config_products(productType);
        ALTER TABLE "products_info" ADD CONSTRAINT products_info_fk2 FOREIGN KEY (creatorId) REFERENCES creators(creatorId);
        ALTER TABLE "products_info" ADD CONSTRAINT products_info_fk3 FOREIGN KEY (instrumentId) REFERENCES instruments(instrumentId);
        ALTER TABLE "products_info" ADD CONSTRAINT products_info_fk4 FOREIGN KEY (obsMode) REFERENCES observation_modes(obsMode);</pre>
      </td>
    </tr>
  </tbody>
</table>
<p> </p>
<h4>Sample QPF Configuration<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Sample_QPF_Configuration</ac:parameter></ac:structured-macro></h4>
<p>This configuration has been actually used in the testing of the QPF V1.0 RC1.</p>
<table bgcolor="#F5ECCE" border="1">
  <tbody>
    <tr>
      <td>
        <pre>        {
            "general": {
                "app_name": "QPF",
                "app_version": "1.0rc2",
                "last_access": "20150616T121555",
                "run_path": "/home/eucops/qpf/run"
            },
            "nodes" : {
                "hmi_node" : "QPFHMI",
                "master_machine" : "eucdev02.net3.lan",
                "node_list" : {
                    "DataMng" : { "client" : "<a href="tcp://10.66.180.97:7101">tcp://10.66.180.97:7101</a>", "server" : "tcp://*:7101", "type" : "datamng" },
                    "EvtMng" : { "client" : "<a href="tcp://10.66.180.97:7100">tcp://10.66.180.97:7100</a>", "server" : "tcp://*:7100", "type" : "evtmng" },
                    "LogMng" : { "client" : "<a href="tcp://10.66.180.97:7102">tcp://10.66.180.97:7102</a>", "server" : "tcp://*:7102", "type" : "logmng" },
                    "QPFHMI" : { "client" : "<a href="tcp://10.66.180.97:7999">tcp://10.66.180.97:7999</a>", "server" : "tcp://*:7999", "type" : "hmi" },
                    "TskMng" : { "client" : "<a href="tcp://10.66.180.97:7104">tcp://10.66.180.97:7104</a>", "server" : "tcp://*:7104", "type" : "taskmng" },
                    "TskOrc" : { "client" : "<a href="tcp://10.66.180.97:7103">tcp://10.66.180.97:7103</a>", "server" : "tcp://*:7103", "type" : "taskorc" },
                    "TskAge1" : { "client" : "<a href="tcp://10.66.180.97:7111">tcp://10.66.180.97:7111</a>", "server" : "tcp://*:7111", "type" : "taskagent" },
                    "TskAge2" : { "client" : "<a href="tcp://10.66.180.97:7112">tcp://10.66.180.97:7112</a>", "server" : "tcp://*:7112", "type" : "taskagent" },
                    "TskAge3" : { "client" : "<a href="tcp://10.66.180.95:7113">tcp://10.66.180.95:7113</a>", "server" : "tcp://*:7113", "type" : "taskagent" },
                    "TskAge4" : { "client" : "<a href="tcp://10.66.180.95:7114">tcp://10.66.180.95:7114</a>", "server" : "tcp://*:7114", "type" : "taskagent" },
                    "TskAge5" : { "client" : "<a href="tcp://10.66.180.95:7115">tcp://10.66.180.95:7115</a>", "server" : "tcp://*:7115", "type" : "taskagent" },
                    "TskAge6" : { "client" : "<a href="tcp://10.66.180.95:7116">tcp://10.66.180.95:7116</a>", "server" : "tcp://*:7116", "type" : "taskagent" },
                    "TskAge7" : { "client" : "<a href="tcp://10.66.180.95:7117">tcp://10.66.180.95:7117</a>", "server" : "tcp://*:7117", "type" : "taskagent" }
                }
            },
            "machines" : {
                "eucdev02.net3.lan" : [ "QPFHMI", "EvtMng", "DataMng", "LogMng", "TskOrc", "TskMng", "TskAge1", "TskAge2" ],
                "eucdev03.net3.lan" : [ "TskAge3", "TskAge4", "TskAge5", "TskAge6", "TskAge7" ]
            },
            "connections" : {
                "DataMng" : [ "EvtMng", "TskMng", "TskOrc" ],
                "EvtMng" : [ "QPFHMI", "DataMng", "LogMng", "TskMng", "TskOrc", "TskAge1", "TskAge2", "TskAge3", "TskAge4", "TskAge5", "TskAge6", "TskAge7" ],
                "LogMng" : [ "EvtMng", "TskAge1", "TskAge2", "TskAge3", "TskAge4", "TskAge5", "TskAge6", "TskAge7" ],
                "QPFHMI" : [ "EvtMng" ],
                "TskAge1" : [ "EvtMng", "LogMng", "TskMng" ],
                "TskAge2" : [ "EvtMng", "LogMng", "TskMng" ],
                "TskAge3" : [ "EvtMng", "LogMng", "TskMng" ],
                "TskAge4" : [ "EvtMng", "LogMng", "TskMng" ],
                "TskAge5" : [ "EvtMng", "LogMng", "TskMng" ],
                "TskAge6" : [ "EvtMng", "LogMng", "TskMng" ],
                "TskAge7" : [ "EvtMng", "LogMng", "TskMng" ],
                "TskMng" : [ "EvtMng", "TskOrc", "DataMng", "TskAge1", "TskAge2", "TskAge3", "TskAge4", "TskAge5", "TskAge6", "TskAge7" ],
                "TskOrc" : [ "EvtMng", "TskMng", "DataMng" ]
            },
            "db": {
                "host": "127.0.0.1",
                "port": "5432",
                "name": "qpfdb",
                "user": "eucops",
                "pwd": ""
            },
            "products": {
                "product_types": [
                    "VIS_RAW",
                    "VIS_INFO",
                    "VIS_LE1",
                    "VIS_LE1_LOG",
                    "VIS_LE1_META",
                    "VIS_LE1_INGLOG",
                    "NIR_RAW",
                    "NIR_INFO",
                    "NIR_LE1",
                    "NIR_LE1_LOG",
                    "NIR_LE1_META",
                    "NIR_LE1_INGLOG",
                    "SIR_RAW",
                    "SIR_INFO",
                    "SIR_LE1",
                    "SIR_LE1_LOG",
                    "SIR_LE1_META",
                    "SIR_LE1_INGLOG",
                    "HK_RAW",
                    "HK_QLA",
                    "UNKNOWN_TYPE"],
                "parsing_regex": "@filenamespec.tpl",
                "parsing_assign": "%T=1+2;%I=1;%S=3;%D=4;%f=4;%v=5",
                "product_id_tpl": "%M_%T_%S_%f",
                "data_ext": "fits",
                "meta_ext": "xml",
                "log_ext": "log"
            },
            "orchestration": {
                "rules": {
                    "VIS_LE1_Processing": {
                        "inputs": "VIS_RAW",
                        "outputs": "VIS_LE1,VIS_LE1_LOG",
                        "processing": "LE1_VIS_Processor",
                        "condition": "1"
                    },
                    "VIS_LE1_MetadataCollection": {
                        "inputs": "VIS_INFO",
                        "outputs": "VIS_LE1_META",
                        "processing": "LE1_VIS_MetadataCollector",
                        "condition": "1"
                    },
                    "VIS_LE1_Ingestion": {
                        "inputs": "VIS_LE1,VIS_LE1_META",
                        "outputs": "VIS_LE1_INGLOG",
                        "processing": "LE1_VIS_Ingestor",
                        "condition": "(VIS_LE1.date==VIS_LE1_META.date) &amp; (VIS_LE1.time==VIS_LE1_META.time)"
                    }
                }
            },
            "processing": {
                "processors": {
                    "LE1_VIS_Processor": {
                        "exe_path": "/opt/pe/bin",
                        "input_path": "/opt/pe/input",
                        "name": "LE1_VIS_Processor",
                        "output_path": "/opt/pe/output"
                    },
                    "LE1_VIS_MetadataCollector": {
                        "exe_path": "/opt/pe/bin",
                        "input_path": "/opt/pe/input",
                        "name": "LE1_VIS_MetadataCollector",
                        "output_path": "/opt/pe/output"
                    },
                    "LE1_VIS_Ingestor": {
                        "exe_path": "/opt/pe/bin",
                        "input_path": "/opt/pe/input",
                        "name": "LE1_VIS_Ingestor",
                        "output_path": "/opt/pe/output"
                    }
                }
            },
            "storage": {
                "base": {
                    "path": "/home/eucops/qpf/run"
                },
                "incoming": {
                    "protocol": "NOTUSED",
                    "address":  "0.0.0.0",
                    "port":     "0",
                    "user":     "xxxxx",
                    "password": "yyyyy",
                    "path":     "/home/eucops/qpf/data/inbox"
                },
                "local_archive": {
                    "path": "/home/eucops/qpf/data/archive"
                },
                "archive": {
                    "protocol": "SCP",
                    "address":  "eucdev.n1data.lan",
                    "port":     "",
                    "user":     "eucops",
                    "password": "",
                    "path":     "/home/eucops/ws/jcgg/DSS_EAS_Proxy/incoming"
                },
                "gateway": {
                    "path": "/home/eucops/qpf/data/gateway"
                },
                "outgoing": {
                    "protocol": "NOTUSED",
                    "address":  "0.0.0.0",
                    "port":     "0",
                    "user":     "xxxxx",
                    "password": "yyyyy",
                    "path":     "/home/eucops/qpf/data/outbox"
                }
            }
        }
        </pre>
      </td>
    </tr>
  </tbody>
</table>
<h4>Alarm System<ac:structured-macro ac:name="anchor"><ac:parameter ac:name="">Alarm_System</ac:parameter></ac:structured-macro></h4>
<p>The QPF includes an Alarm System with the following components:</p>
<ul>
  <li>Alarm Database: The Alarm Database stores:<ul>
      <li>the values of the registered variables with their validity ranges</li>
      <li>the list of alarms and raised, and their current status</li>
      <li>In order to create the database with PostgresSQL, the following must be used</li>
    </ul>
  </li>
  <li>Database Controller: A Database Controller (DBController), that allows variable registration and provides information on current alarms, upon request from a DBClient.</li>
</ul>
<p>This Alarm System is yet to be implemented</p>
